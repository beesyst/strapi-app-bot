# Strapi-App-Bot (SAB)

**SAB** — модульная платформа для сбора, агрегации и структурирования данных о крипто-проектах, с поддержкой автоматического парсинга сайтов, X (Twitter), сервисов коллекций типа linktr.ee и очистки данных. Позволяет централизованно управлять настройками, генерировать отчеты, масштабировать сбор и анализировать любые проекты.

## Основные возможности

* **Модульная архитектура** — плагины для сайтов, X-профилей, коллекционных сервисов.
* **Гибкая обработка ссылок** — парсинг из био, коллекционных страниц, генерация и автоматическая нормализация (очистка хвостов, единый формат для YouTube, docs, GitHub и др.).
* **Централизованная настройка** — все параметры и добавление новых проектов в одном `config.json`.
* **Мультиязычность** — легко добавлять новые языки интерфейса.
* **Полная автоматизация** — запуск одной командой, без ручного вмешательства.
* **Обход защит сайтов** — автоматический переход на браузерный режим при Cloudflare, JS-challenge, антиботах.
* **Асинхронная и быстрая обработка** — все этапы пайплайна работают параллельно.
* **Кэширование данных** — минимизация повторных запросов, ускорение парсинга.
* **Логирование** — подробный лог всех шагов для отладки и аудита.

## Где можно использовать

* **Агрегация и мониторинг крипто- и IT-проектов**
* **Автоматизация сбора контактных данных**
* **Обновление витрин и агрегаторов проектов**
* **Парсинг публичных профилей и документации**

## Технологический стек

* **Python** — основной язык разработки
* **Requests, BeautifulSoup** — парсинг и обработка сайтов
* **Playwright** — парсинг X-профилей (через fingerprint)

### Поддерживаемые источники

| Источник          | Описание                                  |
|-------------------|-------------------------------------------|
| `website`         | Главный сайт проекта                      |
| `docs`            | Документация, whitepaper                  |
| `X/Twitter`       | Bio и линки профиля, аватар               |
| `linktr.ee`/etc.  | Сбор всех связанных соцсетей              |
| `YouTube`         | Корректная агрегация только каналов       |
| `GitHub`          | Поддержка фильтрации только по org/user   |

## Архитектура

### Компоненты системы

1. **Парсеры (`core/*.py`)** — обертки над разными источниками (сайты, коллекционные сервисы, X/Twitter).
2. **Центральная точка входа (`config/start.py`)** — управляет пайплайном сбора, нормализации и сохранения данных.
3. **Шаблоны (`templates/`)** — структуруют результат под формат системы.
4. **Логирование (`logs/`)** — ведет полный журнал работы.
5. **Конфигурация (`config/config.json`)** — все цели, настройки и параметры.

### Структура проекта

```
strapi-app-bot/
├── config/
│   ├── apps/
│   │   └── {project}.json         # Конфиг отдельного приложения
│   ├── config.json                # Центральная конфигурация (все проекты, параметры)
│   └── start.py                   # Главный скрипт пайплайна (точка входа, orchestration)
├── core/
│   ├── api/                       # Интеграции с внешними API
│   │   ├── ai.py                  # Интеграция с AI
│   │   ├── coingecko.py           # Интеграция с CoinGecko
│   │   └── strapi.py              # Интеграция с Strapi CMS
│   ├── parser/                    # Все парсеры контента
│   │   ├── browser_fetch.js       # Playwright + Fingerprint Suite (обход защиты)
│   │   ├── link_aggregator.py     # Linktree, Read.cv и другие агрегаторы
│   │   ├── twitter_scraper.js     # X/Twitter scraper (Node.js)
│   │   ├── twitter.py             # Python-логика X/Twitter (Nitter-first, fallback Playwright)
│   │   ├── web.py                 # Универсальный веб-парсер (requests + BeautifulSoup)
│   │   └── youtube.py             # YouTube-парсер
│   ├── collector.py               # Сбор и агрегация данных (централизатор)
│   ├── install.py                 # Автоустановка зависимостей (Python + Node + Playwright)
│   ├── log_utils.py               # Централизованное логирование
│   ├── normalize.py               # Нормализация данных (общие правила)
│   ├── orchestrator.py            # Оркестрация (главный async pipeline)
│   ├── paths.py                   # Абсолютные пути
│   ├── seo_utils.py               # Заполнение SEO-данных
│   └── status.py                  # Управление статусами пайплайна
├── logs/
│   ├── ai.log                     # Лог AI
│   ├── host.log                   # Хостовой лог пайплайна
│   ├── setup.log                  # Лог установки зависимостей
│   └── strapi.log                 # Лог отправки в Strapi
├── storage/
│   └── apps/
│       └── {project}/
│           └── main.json          # Результаты парсинга по проекту
├── templates/
│   └── main_template.json         # Шаблон структуры main.json
├── requirements.txt               # Python зависимости
├── README.md                      # Документация
└── start.sh                       # Bash-скрипт быстрого запуска пайплайна
```

## Pipeline: Как это работает?

1. **Запуск системы**:
   * `start.sh` → `config/start.py` → `core/orchestrator.py`
2. **Автоустановка зависимостей**:
   * `config/start.py` вызывает `core/install.py`:
      * Проверяет наличие `venv`, создаёт при отсутствии.
      * Устанавливает Python-зависимости (`requirements.txt`).
      * Устанавливает Node.js-модули (`core/package.json`).
      * Загружает Playwright-браузеры (`npx playwright install`).
3. **Загрузка конфигурации и шаблонов**:
   * Загружается основной конфиг (`config/config.json`): цели, параметры, API-ключи.
   * Подтягивается шаблон `templates/main_template.json` для унифицированной структуры `main.json`.
4. **Асинхронный парсинг и сбор данных**:
   * **Web-парсинг:** `core/parser/web.py` (requests + BeautifulSoup).
   * **Обход защиты:** `core/parser/browser_fetch.js` (Playwright + Fingerprint Suite).
   * **Twitter/X:**  
     - `core/parser/twitter.py` (Nitter-first, fallback Playwright).  
     - `core/parser/twitter_scraper.js` (Node.js парсер).  
   * **Link-агрегаторы:** `core/parser/link_aggregator.py`.
   * **YouTube и docs:** `core/parser/youtube.py` и др.
   * **Collector:** `core/collector.py` собирает результаты в единый поток.
   * **Асинхронность:** всё работает через asyncio + ThreadPool.
   * **Кэширование HTML и ретраи:** встроено для ускорения и отказоустойчивости.
5. **AI-генерация и enrichment**:
   * AI создаёт краткие/полные описания.
   * CoinGecko API обогащает токен-данные (fallback — ручные шаблоны).
   * AI подбирает категории, которые автоматически мапятся на Strapi-ID.
6. **Сохранение результата**:
   * Все данные сохраняются в `storage/apps/{app}/{project}/main.json`.
   * Лого/аватары Twitter — в `storage/apps/{app}/{project}/`.
7. **Интеграция со Strapi**:
   * `main.json` заливается через Strapi API.
   * Картинки/лого прикрепляются автоматически.
   * SEO-поля обновляются.

**Запускать нужно только `start.sh` — все остальное сделает бот!**

## Установка и запуск

```bash
git clone https://github.com/beesyst/strapi-app-bot.git
cd strapi-app-bot
bash start.sh
```

## Настройка конфигурации

Все параметры задаются в файле `config/config.json`:

### Общие

| Параметр         | Значение по умолчанию | Описание                                                        |
|------------------|-----------------------|-----------------------------------------------------------------|
| `apps`           | `[ "babylon" ]`       | Список целей (объектов-проектов с настройками и флагом enabled) |
| `enabled`        | `true`                | Флаг: включен ли проект (false — будет проигнорирован)          |
| `link_collections` | `[ "linktr.ee" ]`   | Массив сервисов для глубокого парсинга                          |
| `clear_logs`     | `true`                | Очищать ли логи при старте                                      |

### AI

| Параметр              | Значение по умолчанию | Описание                                                                 |
|-----------------------|-----------------------|--------------------------------------------------------------------------|
| `ai.providers`        | `openai`, `perplexity`| Подключаемые AI-провайдеры и ключи                                       |
| `ai.groups`           | см. config            | Группы генерации (свои модели, промпты, web_search_options)              |
| `short_desc`          | `max_len=130`         | Ограничения длины описания проекта                                       |
| `seo_short`           | `max_len=50`          | Ограничения длины короткого SEO-текста                                   |

### Strapi

| Параметр              | Значение по умолчанию | Описание                                                |
|-----------------------|-----------------------|---------------------------------------------------------|
| `strapi_sync`         | `true`                | Синхронизировать ли данные с Strapi                     |
| `strapi_publish`      | `true`                | Автоматически публиковать записи                        |
| `http_timeout_sec`    | `45`                  | Таймаут HTTP-запросов к Strapi                          |
| `http_retries`        | `3`                   | Кол-во повторных попыток при ошибках                    |
| `http_backoff`        | `1.7`                 | Множитель для задержки между ретраями                   |

### Nitter (X/Twitter парсер)

| Параметр                   | Значение по умолчанию | Описание                                      |
|----------------------------|-----------------------|-----------------------------------------------|
| `nitter_instances`         | список URL            | Список инстансов Nitter                       |
| `nitter_retry_per_instance`| `1`                   | Сколько раз пробовать на каждом инстансе      |
| `nitter_timeout_sec`       | `14`                  | Таймаут запросов                              |
| `nitter_bad_ttl_sec`       | `600`                 | TTL для кэширования неудачных попыток (сек)   |
| `nitter_enabled`           | `true`                | Включен ли парсинг через Nitter               |

### CoinGecko

| Параметр       | Значение по умолчанию                     | Описание                      |
|----------------|-------------------------------------------|-------------------------------|
| `api_base`     | `https://api.coingecko.com/api/v3`        | Базовый URL API CoinGecko     |

### Прочее

| Параметр            | Описание                                                |
|---------------------|---------------------------------------------------------|
| `bad_name_keywords` | Список стоп-слов для фильтрации некорректных project.name |
| `categories`        | Список категорий для проектов                           |


## Терминал и статусы

В процессе работы бот выводит для каждого проекта только итоговый статус:

* `[add]` — проект добавлен впервые (создан новый main.json, отправлен в Strapi)
* `[update]` — данные проекта обновлены (main.json перезаписан, отправлен в Strapi)
* `[skip]` — данные не изменились (ничего не отправлялось)
* `[error]` — возникла ошибка при сборе или отправке

